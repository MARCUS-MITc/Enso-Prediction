{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import importlib\n",
    "from preprocessingtesting import DataPreprocessortesting\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ea0ca-05a9-4ccc-a1a0-7450fc919399",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load('weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47aab67-fd29-4b0e-b4e5-a91134135584",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_models.pkl', 'rb') as f:\n",
    "    best_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cc575-95b1-44cb-a5b9-40afd38a62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = best_models['jjas_Avg']\n",
    "second_model = best_models['Jun']\n",
    "third_model = best_models['Jul']\n",
    "fourth_model = best_models['Aug']\n",
    "fifth_model = best_models['Sep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b610f41-86f6-485d-bf75-9b2a1c28cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_correlation_data.pkl', 'rb') as f:\n",
    "    sorted_correlation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80da15-9f8f-40c8-bfe0-57071074391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sorted_correlation_data['sorted_correlation_pearson']\n",
    "k = sorted_correlation_data['sorted_correlation_kendall']\n",
    "s = sorted_correlation_data['sorted_correlation_spearman']\n",
    "m = sorted_correlation_data['sorted_correlation_mutual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_scalers.pkl', 'rb') as f:\n",
    "    best_scalers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_mean.pkl', 'rb') as f:\n",
    "    long_term_mean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaaddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_anomalies.pkl', 'rb') as f:\n",
    "    long_term_anomalies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, nc_file, weights,means,anomalies, correlation_file,best_model,best_scaler,top_n):\n",
    "        \n",
    "        self.preprocessor = DataPreprocessortesting(nc_file,means,anomalies)\n",
    "        self.autoencoder_input_data = self.preprocessor.execute_pipeline()\n",
    "        self.weights = weights\n",
    "        self.correlation_file = correlation_file\n",
    "        self.best_model = best_model\n",
    "        self.best_scaler = best_scaler\n",
    "        self.top_n = top_n\n",
    "        self.means = means\n",
    "        self.anomalies = anomalies\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def convert_to_april_march(self,month_idx):\n",
    "        \n",
    "        return (month_idx-3) % 12 \n",
    "    \n",
    "    \n",
    "    def Tweights(self,weight):\n",
    "        threshold_values = []\n",
    "        for threshold_multiplier in np.arange(2, 1, -0.1):\n",
    "            num = []\n",
    "            for i in range(weight.shape[1]):\n",
    "                weight_mean = np.mean(weight[:, i])\n",
    "                weight_std = np.std(weight[:, i])\n",
    "                threshold_upper = weight_mean + threshold_multiplier * weight_std\n",
    "                threshold_lower = weight_mean - threshold_multiplier * weight_std\n",
    "                nodes_with_weight_above_upper_threshold = np.sum(weight[:, i] > threshold_upper)\n",
    "                nodes_with_weight_below_lower_threshold = np.sum(weight[:, i] < threshold_lower)\n",
    "                ten_percent_nodes = int(0.1 * weight.shape[0])\n",
    "\n",
    "                if (nodes_with_weight_above_upper_threshold + nodes_with_weight_below_lower_threshold) > ten_percent_nodes:\n",
    "                    num.append(nodes_with_weight_above_upper_threshold + nodes_with_weight_below_lower_threshold)\n",
    "                    #print(i, nodes_with_weight_above_upper_threshold, threshold_upper, nodes_with_weight_below_lower_threshold, threshold_lower)\n",
    "\n",
    "                    if len(num) == weight.shape[1]:\n",
    "                        threshold_values.append(threshold_multiplier)\n",
    "                        break\n",
    "            if len(num) == weight.shape[1]:\n",
    "                break\n",
    "\n",
    "        return threshold_values\n",
    "    \n",
    "        \n",
    "    def potential_pred(self,threshold_values,input_data,weights):\n",
    "        pred = np.zeros((65,input_data.shape[0]))\n",
    "        for i in range(weights.shape[1]):\n",
    "            weight_mean = np.mean(weights[:,i])\n",
    "            weight_std = np.std(weights[:,i])\n",
    "            threshold_upper = weight_mean + threshold_values[0] * weight_std\n",
    "            threshold_lower = weight_mean - threshold_values[0] * weight_std\n",
    "            nodes_with_weight_above_upper_threshold = np.sum(weights[:, i] > threshold_upper)\n",
    "            nodes_with_weight_below_lower_threshold = np.sum(weights[:, i] < threshold_lower)\n",
    "            ten_percent_nodes = int(0.1 * weights.shape[0])\n",
    "            if (nodes_with_weight_above_upper_threshold + nodes_with_weight_below_lower_threshold) > ten_percent_nodes:\n",
    "                for h in range(input_data.shape[0]): \n",
    "                    pred_i = 0\n",
    "                    for j in range(weights.shape[0]):\n",
    "                        weight_value = weights[j,i]\n",
    "                        if weight_value > threshold_upper or weight_value < threshold_lower:\n",
    "                            pp = np.sum(weight_value*input_data[h,j])\n",
    "                            pred_i += pp\n",
    "                            pred[i,h] = pred_i\n",
    "        return pred\n",
    "        \n",
    "    def get_pred_values(self):\n",
    "        x_test = []\n",
    "        for idx, month_idx, value in self.correlation_file:\n",
    "            month_idx_april_march = self.convert_to_april_march(month_idx)\n",
    "            if month_idx_april_march in [0, 1]:\n",
    "                continue\n",
    "            pred_value = self.pred[idx, month_idx_april_march]\n",
    "            if len(x_test) >= self.top_n:\n",
    "                break\n",
    "            x_test.append(pred_value)\n",
    "\n",
    "        return np.array(x_test).reshape(-1, 1)\n",
    "    \n",
    "    def predict(self):\n",
    "        th = self.Tweights(self.weights)\n",
    "        self.autoencoder_input_data = self.autoencoder_input_data.reshape(-1, 324)\n",
    "        self.pred = self.potential_pred(th,self.autoencoder_input_data, self.weights)\n",
    "        x_test0 = self.get_pred_values( )\n",
    "        #scaler = StandardScaler()\n",
    "        x_test0_reshaped = x_test0.reshape(1, -1)\n",
    "        X_new_scaled = self.best_scaler.transform(x_test0_reshaped)\n",
    "        \n",
    "        predictions = self.best_model.predict(X_new_scaled)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab759f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_mam = Predictor('Air_test.nc', 'weights.npy', p,first_model,15)\n",
    "prediction_MAMmean = predictor_mam.predict()\n",
    "prediction_MAMmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e39dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_june = Predictor('Air_test.nc',weights,long_term_mean,long_term_anomalies, p,second_model,second_scalar,20)\n",
    "predictor_june = predictor_june.predict()\n",
    "predictor_june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce14600",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_ = Predictor('Air_test.nc', 'weights.npy', p,third_model,15)\n",
    "prediction_april = predictor_april.predict()\n",
    "prediction_april"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_may = Predictor('Air_test.nc', 'weights.npy', p,fourth_model,15)\n",
    "prediction_may = predictor_may.predict()\n",
    "prediction_may"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

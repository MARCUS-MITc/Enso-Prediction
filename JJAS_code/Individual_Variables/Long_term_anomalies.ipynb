{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import num2date,date2index\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import num2date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83eb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, nc_file):\n",
    "        self.nc_file = nc_file\n",
    "\n",
    "    def preprocessing(self):\n",
    "        data = nc.Dataset(self.nc_file)\n",
    "        variable_names = list(data.variables.keys())\n",
    "        latitude = data.variables[variable_names[2]][:]\n",
    "        longitude = data.variables[variable_names[1]][:]\n",
    "        time_var = data.variables['time']\n",
    "        dates = num2date(time_var[:], units=time_var.units, calendar=time_var.calendar)\n",
    "        variable = data.variables[variable_names[3]][:, :, :]\n",
    "        data_ = np.array(variable)\n",
    "        data_[data_ == -9.96921e+36] = 0\n",
    "        data_ = data_[:-12,:,:]\n",
    "        data_reshaped = np.reshape(data_, (len(data_) // 12, 12, data_.shape[1], data_.shape[2]))\n",
    "        print(\"Start date:\", dates[0])\n",
    "        print(\"End date:\", dates[-1])\n",
    "        return data_reshaped, latitude, longitude\n",
    "\n",
    "    def lon_pp(self, longitude):\n",
    "        lon_indices = []\n",
    "        for start_value in np.arange(0, 360, 20):\n",
    "            end_value = start_value + 20\n",
    "            range_indices = np.where((longitude >= start_value) & (longitude < end_value))[0]\n",
    "            if len(range_indices) > 0:\n",
    "                min_index = range_indices[np.argmin(longitude[range_indices])]\n",
    "                max_index = range_indices[np.argmax(longitude[range_indices])]\n",
    "                lon_indices.append(min_index)\n",
    "                lon_indices.append(max_index)\n",
    "        return lon_indices\n",
    "\n",
    "    def lat_pp(self, latitude):\n",
    "        lat_indices = []\n",
    "        for start_value in np.arange(90, -90, -10):\n",
    "            end_value = start_value - 10\n",
    "            range_indices = np.where((latitude <= start_value) & (latitude > end_value))[0]\n",
    "            if len(range_indices) > 0:\n",
    "                min_index = range_indices[np.argmax(latitude[range_indices])]\n",
    "                max_index = range_indices[np.argmin(latitude[range_indices])]\n",
    "                lat_indices.append(min_index)\n",
    "                lat_indices.append(max_index)\n",
    "        return lat_indices\n",
    "\n",
    "    def coarse_gridding(self, data, lat_indices, lon_indices):\n",
    "        coarsed_data = np.zeros((data.shape[0], data.shape[1], len(lat_indices) // 2, len(lon_indices) // 2))\n",
    "        for lat_idx in range(0, len(lat_indices), 2):\n",
    "            lat_range_start = lat_indices[lat_idx]\n",
    "            lat_range_end = lat_indices[lat_idx + 1]\n",
    "            for lon_idx in range(0, len(lon_indices), 2):\n",
    "                lon_range_start = lon_indices[lon_idx]\n",
    "                lon_range_end = lon_indices[lon_idx + 1]\n",
    "                subset = data[:, :, lat_range_start:lat_range_end, lon_range_start:lon_range_end]\n",
    "                averaged_value = np.mean(subset, axis=(2, 3))\n",
    "                coarsed_data[:, :, lat_idx // 2, lon_idx // 2] = averaged_value\n",
    "        final = np.reshape(coarsed_data, (len(coarsed_data), 12, coarsed_data.shape[2]*coarsed_data.shape[3]))\n",
    "        return final\n",
    "\n",
    "    def calculate_monthly_anomalies(self, data):\n",
    "        anomalies = np.zeros((data.shape[0], data.shape[1], data.shape[2]))\n",
    "        means = np.zeros((data.shape[1], data.shape[2]))\n",
    "        for i in range(data.shape[2]):\n",
    "            for j in range(data.shape[1]):\n",
    "                month = data[:, j, i]\n",
    "                monthly_mean = np.mean(month)\n",
    "                means[j, i] = monthly_mean\n",
    "                anomalies[:, j, i] = month - monthly_mean\n",
    "                \n",
    "\n",
    "        return means,anomalies\n",
    "    \n",
    "    def execute(self):\n",
    "        data, latitude, longitude = self.preprocessing()\n",
    "        lon_indices = self.lon_pp(longitude)\n",
    "        lat_indices = self.lat_pp(latitude)\n",
    "        final_data = self.coarse_gridding(data, lat_indices, lon_indices)\n",
    "        monthly_means,anomalies_ = self.calculate_monthly_anomalies(final_data)\n",
    "        monthly_means= monthly_means.reshape(1,12,324)\n",
    "        return monthly_means,anomalies_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff3105",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPreprocessor(\"AIRT2023.nc\")\n",
    "means,anomalies = processor.execute()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24593aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_mean.pkl', 'wb') as f:\n",
    "    pickle.dump(means, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ad0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_mean.pkl', 'rb') as f:\n",
    "    long_term_mean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_anomalies.pkl', 'wb') as f:\n",
    "    pickle.dump(anomalies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e5897",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_anomalies.pkl', 'rb') as f:\n",
    "    long_term_anomalies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f0f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

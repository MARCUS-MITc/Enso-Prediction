{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from  Auto_encoders import AutoEncoder\n",
    "from preprocessing import DataPreprocessor\n",
    "from Predictors import CorrelationAnalysis\n",
    "from Model_Training_boosting_RMSE import ENSOAnalysis_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class execute:\n",
    "    \n",
    "    def __init__(self, nc_file, enso_file):\n",
    "        self.nc_file = nc_file\n",
    "        self.enso_file = enso_file\n",
    "    \n",
    "    def ploting_correlation(self):\n",
    "        autoencoder = AutoEncoder()\n",
    "        preprocessor = DataPreprocessor(self.nc_file)\n",
    "        autoencoder_input_data = preprocessor.execute_pipeline()\n",
    "        autoencoder.fit_autoencoder(autoencoder_input_data)\n",
    "        weights = autoencoder.weights\n",
    "        input_data = autoencoder.input_data\n",
    "        correlation_analyzer = CorrelationAnalysis(input_data, weights, self.enso_file )\n",
    "        top_predictions, sorted_correlation_data = correlation_analyzer.run_correlation_analysis()\n",
    "        pearson = top_predictions['top_pred_pearson']\n",
    "        kendall = top_predictions['top_pred_kendall']\n",
    "        spearman = top_predictions['top_pred_spearman']\n",
    "        mutual = top_predictions['top_pred_mutual']\n",
    "        correlations = [pearson, kendall, spearman, mutual]\n",
    "        analysis = ENSOAnalysis_br(correlations, self.enso_file)\n",
    "        analysis.execute_analysis(['mam_Avg','Mar', 'Apr','May'])\n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e4dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nc_file = \"AIRT2023.nc\"\n",
    "enso_file = \"enso2023.csv\"\n",
    "\n",
    "# Create an instance of the execute class\n",
    "executor = execute(nc_file, enso_file)\n",
    "\n",
    "# Call the ploting_correlation method\n",
    "analysis = executor.ploting_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_models_boosting_rmse.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.best_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075da591",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_models_boosting_rmse.pkl', 'rb') as f:\n",
    "    best_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f7edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_scalers_boosting_rmse.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_scalers_boosting_rmse.pkl', 'rb') as f:\n",
    "    best_scalers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168620b-2645-4419-bcd1-c5bf67f5406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_preds_boosting_rmse.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.y_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a499e04-8ccf-4306-9d14-c45b3fb7880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_preds_boosting_rmse.pkl', 'rb') as f:\n",
    "   best_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb6f9b-9685-4151-b3d5-8f3b6614d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_tests_boosting_rmse.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.y_tests, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5ee03-5e32-4acb-a333-51a662ac88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_tests_boosting_rmse.pkl', 'rb') as f:\n",
    "   best_tests = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a7a17-b17e-4bb6-9b7a-259608ad2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_categorical(data):\n",
    "  \"\"\"\n",
    "  Converts numerical data to categorical (0 for < 0, 1 otherwise).\n",
    "\n",
    "  Args:\n",
    "      data (np.ndarray): The data to be converted.\n",
    "\n",
    "  Returns:\n",
    "      np.ndarray: The converted categorical data.\n",
    "  \"\"\"\n",
    "  return np.where(data < 0, 0, 1)\n",
    "\n",
    "# Apply the conversion to y_pred and y_test\n",
    "y_pred_categorical = convert_to_categorical(best_preds_Aug)\n",
    "y_test_categorical = convert_to_categorical(best_tests_Aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d723a5a-74d7-427b-9d64-6d6c183ceba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_categorical\n",
    "y_test = y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4183855-e0da-4f3a-aeb6-076ffa223f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Example data (replace this with your actual y_test and y_pred)\n",
    "# Calculate metrics\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "# Calculate Sensitivity\n",
    "TP = conf_matrix[1, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "# Calculate Specificity\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "# Calculate Negative Predictive Rate\n",
    "negative_predictive_rate = TN / (TN + FN)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Metric': ['RMSE','Sensitivity','Specificity','Precision','Negative Predictive Rate','Accuracy','F1 Score'],\n",
    "    'MARCH': [.32,sensitivity,specificity,precision, negative_predictive_rate,accuracy, f1]\n",
    "}\n",
    "metrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv('model_metrics_March_boosting.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

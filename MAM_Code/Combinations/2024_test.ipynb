{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from preprocessingtesting import DataPreprocessortesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_models_boosting.pkl', 'rb') as f:\n",
    "    best_models_boosting = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1050666",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load('weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_correlation_data.pkl', 'rb') as f:\n",
    "    sorted_correlation_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sorted_correlation_data['sorted_correlation_pearson']\n",
    "k = sorted_correlation_data['sorted_correlation_kendall']\n",
    "s = sorted_correlation_data['sorted_correlation_spearman']\n",
    "m = sorted_correlation_data['sorted_correlation_mutual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_mean.pkl', 'rb') as f:\n",
    "    long_term_mean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('long_term_anomalies.pkl', 'rb') as f:\n",
    "    long_term_anomalies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_scalers_boosting.pkl', 'rb') as f:\n",
    "    best_scalers_boosting = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb7e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, nc_file1, nc_file2, weights,means,anomalies, correlation_file, best_model,best_scaler, top_n):\n",
    "        self.processor = DataPreprocessortesting(means,anomalies)\n",
    "        self.nc_file1 = nc_file1\n",
    "        self.nc_file2 = nc_file2\n",
    "        self.autoencoder_input_data = self.processor.execute_pipeline(nc_file1, nc_file2)\n",
    "        self.weights = weights\n",
    "        self.correlation_file = correlation_file\n",
    "        self.best_model = best_model\n",
    "        self.best_scaler = best_scaler\n",
    "        self.top_n = top_n\n",
    "        self.means = means\n",
    "        self.anomalies = anomalies\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def convert_to_april_march(self,month_idx):\n",
    "        \n",
    "        return (month_idx-2) % 12 \n",
    "    \n",
    "    \n",
    "    def Tweights(self,weight):\n",
    "        threshold_values = []\n",
    "        for threshold_multiplier in np.arange(2, 1, -0.1):\n",
    "            num = []\n",
    "            for i in range(weight.shape[1]):\n",
    "                weight_mean = np.mean(weight[:, i])\n",
    "                weight_std = np.std(weight[:, i])\n",
    "                threshold_upper = weight_mean + threshold_multiplier * weight_std\n",
    "                threshold_lower = weight_mean - threshold_multiplier * weight_std\n",
    "                nodes_with_weight_above_upper_threshold = np.sum(weight[:, i] > threshold_upper)\n",
    "                nodes_with_weight_below_lower_threshold = np.sum(weight[:, i] < threshold_lower)\n",
    "                ten_percent_nodes = int(0.1 * weight.shape[0])\n",
    "\n",
    "                if (nodes_with_weight_above_upper_threshold + nodes_with_weight_below_lower_threshold) > ten_percent_nodes:\n",
    "                    num.append(nodes_with_weight_above_upper_threshold + nodes_with_weight_below_lower_threshold)\n",
    "                    #print(i, nodes_with_weight_above_upper_threshold, threshold_upper, nodes_with_weight_below_lower_threshold, threshold_lower)\n",
    "\n",
    "                    if len(num) == weight.shape[1]:\n",
    "                        threshold_values.append(threshold_multiplier)\n",
    "                        break\n",
    "            if len(num) == weight.shape[1]:\n",
    "                break\n",
    "\n",
    "        return threshold_values\n",
    "    \n",
    "        \n",
    "    def potential_pred(self,threshold_values,input_data,weights):\n",
    "        pred = np.zeros((65,input_data.shape[0]))\n",
    "        for i in range(weights.shape[1]):\n",
    "            weight_mean = np.mean(weights[:,i])\n",
    "            weight_std = np.std(weights[:,i])\n",
    "            threshold_upper = weight_mean + threshold_values[0] * weight_std\n",
    "            threshold_lower = weight_mean - threshold_values[0] * weight_std\n",
    "            nodes_with_weight_above_upper_threshold = np.sum(weights[:, i] > threshold_upper)\n",
    "            nodes_with_weight_below_lower_threshold = np.sum(weights[:, i] < threshold_lower)\n",
    "            ten_percent_nodes = int(0.1 * weights.shape[0])\n",
    "            if (nodes_with_weight_above_upper_threshold + nodes_with_weight_below_lower_threshold) > ten_percent_nodes:\n",
    "                for h in range(input_data.shape[0]): \n",
    "                    pred_i = 0\n",
    "                    for j in range(weights.shape[0]):\n",
    "                        weight_value = weights[j,i]\n",
    "                        if weight_value > threshold_upper or weight_value < threshold_lower:\n",
    "                            pp = np.sum(weight_value*input_data[h,j])\n",
    "                            pred_i += pp\n",
    "                            pred[i,h] = pred_i\n",
    "        return pred\n",
    "        \n",
    "    def get_pred_values(self):\n",
    "        \n",
    "        x_test = []\n",
    "        for idx, month_idx, value in self.correlation_file[:self.top_n]:\n",
    "            month_idx_april_march = self.convert_to_april_march(month_idx)\n",
    "            pred_value = self.pred[idx, month_idx_april_march]\n",
    "            x_test.append(pred_value)\n",
    "           \n",
    "        return np.array(x_test).reshape(-1, 1)\n",
    "    \n",
    "    def predict(self):\n",
    "        th = self.Tweights(self.weights)\n",
    "        self.autoencoder_input_data = self.autoencoder_input_data.reshape(-1, self.weights.shape[0])\n",
    "        self.pred = self.potential_pred(th,self.autoencoder_input_data, self.weights)\n",
    "        x_test0 = self.get_pred_values( )\n",
    "        x_test0_reshaped = x_test0.reshape(1, -1)\n",
    "        X_new_scaled = self.best_scaler.transform(x_test0_reshaped)\n",
    "        predictions = self.best_model.predict(X_new_scaled)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab759f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_mar = Predictor('Air_test.nc','Gph_Test.nc', weights,long_term_mean,long_term_anomalies,p,second_model_boosting,second_scalar_boosting,15)\n",
    "prediction_march = predictor_mar.predict()\n",
    "prediction_march"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071434d6-953d-4a57-9c13-9af94517f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_mam = Predictor('SLP_test.nc','Uwind_test.nc', weights,long_term_mean,long_term_anomalies,m,first_model_boosting,first_scalar_boosting,15)\n",
    "prediction_MAMmean = predictor_mam.predict()\n",
    "prediction_MAMmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49bb79-0053-4861-b5bd-cdd46dab38ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

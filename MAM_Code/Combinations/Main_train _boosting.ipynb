{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from  Auto_encoders import AutoEncoder\n",
    "from preprocessing import DataPreprocessor\n",
    "from Predictors import CorrelationAnalysis\n",
    "from Model_Training_boosting import ENSOAnalysis_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class execute:\n",
    "    \n",
    "    def __init__(self, nc_file1, nc_file2, enso_file):\n",
    "        self.nc_file1 = nc_file1\n",
    "        self.nc_file2 = nc_file2\n",
    "        self.enso_file = enso_file\n",
    "    \n",
    "    def ploting_correlation(self):\n",
    "        autoencoder = AutoEncoder()\n",
    "        processor = DataPreprocessor()\n",
    "        autoencoder_input_data = processor.execute_pipeline(self.nc_file1,self.nc_file2)\n",
    "        \n",
    "        autoencoder.fit_autoencoder(autoencoder_input_data)\n",
    "        weights = autoencoder.weights\n",
    "        input_data = autoencoder.input_data\n",
    "        correlation_analyzer = CorrelationAnalysis(input_data, weights, self.enso_file )\n",
    "        top_predictions, sorted_correlation_data = correlation_analyzer.run_correlation_analysis()\n",
    "        pearson = top_predictions['top_pred_pearson']\n",
    "        kendall = top_predictions['top_pred_kendall']\n",
    "        spearman = top_predictions['top_pred_spearman']\n",
    "        mutual = top_predictions['top_pred_mutual']\n",
    "        correlations = [pearson, kendall, spearman, mutual]\n",
    "        analysis = ENSOAnalysis_br(correlations, self.enso_file)\n",
    "        analysis.execute_analysis(['mam_Avg','Mar', 'Apr','May'])\n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file1 = \"AIRT2023.nc\"\n",
    "nc_file2 = \"GPH200.nc\"\n",
    "\n",
    "enso_file = \"enso2023.csv\"\n",
    "\n",
    "# Create an instance of the execute class\n",
    "executor = execute(nc_file1, nc_file2, enso_file)\n",
    "\n",
    "# Call the ploting_correlation method\n",
    "analysis = executor.ploting_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_models_boosting.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.best_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075da591",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_models.pkl', 'rb') as f:\n",
    "    best_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_scalers_boosting.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_scalers.pkl', 'rb') as f:\n",
    "    best_scalers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850b270-b4fa-443d-9fd7-9a0e285f4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_preds.pkl', 'rb') as f:\n",
    "   best_preds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eef526-4902-4b2f-953b-639340533bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_tests.pkl', 'wb') as f:\n",
    "    pickle.dump(analysis.y_tests, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c4658-6dbd-4ce7-ab41-f94acce00408",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y_tests.pkl', 'rb') as f:\n",
    "   best_tests = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a71bc6d-29a3-46bc-9968-57f559801705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_tests_mar = best_tests['Mar']\n",
    "best_tests_mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88f0ce-1e70-44d1-87df-a4b4547ac8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_categorical(data):\n",
    "  \"\"\"\n",
    "  Converts numerical data to categorical (0 for < 0, 1 otherwise).\n",
    "\n",
    "  Args:\n",
    "      data (np.ndarray): The data to be converted.\n",
    "\n",
    "  Returns:\n",
    "      np.ndarray: The converted categorical data.\n",
    "  \"\"\"\n",
    "  return np.where(data < 0, 0, 1)\n",
    "\n",
    "# Apply the conversion to y_pred and y_test\n",
    "y_pred_categorical = convert_to_categorical(best_preds_mar)\n",
    "y_test_categorical = convert_to_categorical(best_tests_mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aba7b9-afd7-42b1-9703-49e8f6092d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_categorical\n",
    "y_test = y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f87844-1b1e-4b4b-8624-db3e5ef1cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Example data (replace this with your actual y_test and y_pred)\n",
    "# Calculate metrics\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "# Calculate Sensitivity\n",
    "TP = conf_matrix[1, 1]\n",
    "FN = conf_matrix[1, 0]\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "# Calculate Specificity\n",
    "TN = conf_matrix[0, 0]\n",
    "FP = conf_matrix[0, 1]\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "# Calculate Negative Predictive Rate\n",
    "negative_predictive_rate = TN / (TN + FN)\n",
    "\n",
    "# Create a DataFrame to store the metrics\n",
    "data = {\n",
    "    'Metric': ['Correlation','Sensitivity','Specificity','Precision','Negative Predictive Rate','Accuracy','F1 Score'],\n",
    "    'MAR': [.94,sensitivity,specificity,precision, negative_predictive_rate,accuracy, f1]\n",
    "}\n",
    "metrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv('model_metrics_Mar.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
